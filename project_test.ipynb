{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install pynrrd numpy torch torchvision monai tensorflow wandb nibabel monai[nibabel] utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import monai\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import nrrd\n",
    "import torch\n",
    "import PIL\n",
    "import IPython.display\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.transforms import (\n",
    "    LoadImage,\n",
    "    LoadImaged,\n",
    "    Spacing,\n",
    "    SaveImage,\n",
    "    EnsureChannelFirst,\n",
    "    SpatialResample)\n",
    "    \n",
    "from monai.data import ImageWriter, MetaTensor\n",
    "from monai.inferers import sliding_window_inference\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_dict_ASOCA(data_path, mode=\"train\"):\n",
    "    # test if mode is correct\n",
    "    if mode not in [\"train\", \"validation\", \"test\", \"secret_test\"]:\n",
    "        raise ValueError(f\"Please choose a mode in ['train', 'validation', 'test']. Current mode is {mode}.\")\n",
    "\n",
    "    # create empty dictionary\n",
    "    dicts = list()\n",
    "\n",
    "    for clazz in [\"Diseased\", \"Normal\"]:\n",
    "        if mode == \"train\":\n",
    "            for index in range(1,17):\n",
    "                image_path = os.path.join(data_path, clazz, \"CTCA\", f\"{clazz}_{index}.nrrd\")\n",
    "                mask_path = os.path.join(data_path, clazz, \"Annotations\", f\"{clazz}_{index}.nrrd\")\n",
    "                dicts.append({\"img\": image_path, \"mask\": mask_path})\n",
    "        if mode == \"validation\":\n",
    "            for index in range(17,21):\n",
    "                image_path = os.path.join(data_path, clazz, \"CTCA\", f\"{clazz}_{index}.nrrd\")\n",
    "                mask_path = os.path.join(data_path, clazz, \"Annotations\", f\"{clazz}_{index}.nrrd\")\n",
    "                dicts.append({\"img\": image_path, \"mask\": mask_path})\n",
    "        if mode == \"test\":\n",
    "            if clazz == \"Diseased\":\n",
    "                for index in range(10,20):\n",
    "                    image_path = os.path.join(data_path, clazz, f\"Testset_Disease\", f\"{index}.nrrd\")\n",
    "                    dicts.append({\"img\": image_path})\n",
    "            else:\n",
    "                for index in range(10):\n",
    "                    image_path = os.path.join(data_path, clazz, f\"Testset_{clazz}\", f\"{index}.nrrd\")\n",
    "                    dicts.append({\"img\": image_path})\n",
    "                    \n",
    "    if mode == \"secret_test\":\n",
    "        for index in range(1,21):\n",
    "            image_path = os.path.join(data_path, f\"{index}.img.nii.gz\")\n",
    "            dicts.append({\"img\": image_path})            \n",
    "    return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Some examples of image sizes and voxel dimensions\n",
    "\n",
    "loader = LoadImage(dtype=np.float32, image_only=True)\n",
    "image = loader(build_dict_ASOCA(\"ASOCA\", mode=\"train\")[0][\"img\"])\n",
    "# print(f\"input: {train_data_dicts[0]['image']}\")\n",
    "print(f\"image shape: {image.shape}\")\n",
    "print(f\"image voxel dim: {image.pixdim}\")\n",
    "image = loader(build_dict_ASOCA(\"ASOCA\", mode=\"validation\")[2][\"img\"])\n",
    "# print(f\"input: {train_data_dicts[0]['image']}\")\n",
    "print(f\"image shape: {image.shape}\")\n",
    "print(f\"image voxel dim: {image.pixdim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# adjust cache_rate based on how much memory you have. test_dataset is only used for visualization / at end, so dont need to cache it\n",
    "# Look at the values for pixdim\n",
    "\n",
    "# Training transforms\n",
    "train_transform = monai.transforms.Compose([\n",
    "    # Load the image with monai's image loader:\n",
    "    monai.transforms.LoadImaged(keys=(\"img\", \"mask\"), image_only=False),\n",
    "    # Add channel since transforms expect a channel dimension:\n",
    "    monai.transforms.EnsureChannelFirstd(keys=['img', 'mask'], channel_dim=\"no_channel\"),\n",
    "    # Create uniform voxel spacing:\n",
    "    monai.transforms.Spacingd(keys=[\"img\", \"mask\"], pixdim=(0.4, 0.4, 0.5), mode=(\"bilinear\", \"nearest\")),\n",
    "    # Random flip and rotate:\n",
    "    monai.transforms.RandFlipd(keys=['img', 'mask'], prob=0.5, spatial_axis=0),\n",
    "    monai.transforms.RandFlipd(keys=['img', 'mask'], prob=0.5, spatial_axis=1),\n",
    "    monai.transforms.RandFlipd(keys=['img', 'mask'], prob=0.5, spatial_axis=2),\n",
    "    monai.transforms.RandRotated(keys=['img', 'mask'], range_x=np.pi/4, prob=0.5, mode=['bilinear', 'nearest']),\n",
    "    # Crop to 128×128×128\n",
    "    monai.transforms.RandSpatialCropd(keys=['img', 'mask'], roi_size=[256,256,128], random_size=False),\n",
    "    monai.transforms.ScaleIntensityRanged(keys=['img'],a_min=0,a_max=1000,b_min=0.0,b_max=1.0,clip=True)\n",
    "])\n",
    "\n",
    "# Validation transforms\n",
    "val_transform = monai.transforms.Compose([\n",
    "    # Load the image with monai's image loader:\n",
    "    monai.transforms.LoadImaged(keys=(\"img\", \"mask\"), image_only=False),\n",
    "    # Add channel since transforms expect a channel dimension:\n",
    "    monai.transforms.EnsureChannelFirstd(keys=['img', 'mask'], channel_dim=\"no_channel\"),\n",
    "    # Create uniform voxel spacing:\n",
    "    monai.transforms.Spacingd(keys=[\"img\", \"mask\"], pixdim=(0.4, 0.4, 0.5), mode=(\"bilinear\", \"nearest\")),\n",
    "    monai.transforms.ScaleIntensityRanged(keys=['img'],a_min=0,a_max=1000,b_min=0.0,b_max=1.0,clip=True)\n",
    "])\n",
    "\n",
    "# Test transforms\n",
    "test_transform = monai.transforms.Compose([\n",
    "    # Load the image with monai's image loader:\n",
    "    monai.transforms.LoadImaged(keys=(\"img\"), image_only=True),\n",
    "    # Add channel since transforms expect a channel dimension:\n",
    "    monai.transforms.EnsureChannelFirstd(keys=['img'], channel_dim=\"no_channel\"),\n",
    "    # Create uniform voxel spacing:\n",
    "    monai.transforms.Spacingd(keys=['img'], pixdim=(0.4, 0.4, 0.5), mode=(\"bilinear\")),\n",
    "    monai.transforms.ScaleIntensityRanged(keys=['img'],a_min=0,a_max=1000,b_min=0.0,b_max=1.0,clip=True)\n",
    "])\n",
    "\n",
    "train_dataset = monai.data.CacheDataset(build_dict_ASOCA(\"ASOCA\", mode=\"train\"), transform=train_transform, num_workers = 8)\n",
    "validation_dataset = monai.data.CacheDataset(build_dict_ASOCA(\"ASOCA\", mode=\"validation\"), transform=val_transform, num_workers =8)\n",
    "secrettest_dataset = monai.data.CacheDataset(build_dict_ASOCA(\"ASOCA_secret\", mode=\"secret_test\"), transform=test_transform, num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if the image size and voxel dimension have correctly changed\n",
    "sample_dict = train_dataset[20]\n",
    "print(\"Size of the image\", sample_dict[\"img\"].shape)\n",
    "print(\"Voxel dim of the image\", sample_dict[\"img\"].pixdim)\n",
    "print(\"Size of the mask\", sample_dict[\"mask\"].shape)\n",
    "print(\"Voxel dim of the mask\", sample_dict[\"mask\"].pixdim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualization options\n",
    "color_actual = [0, 0.5, 0]\n",
    "color_predicted = [0, 0, 0.5]\n",
    "\n",
    "def RGB_mask(mask, color):\n",
    "    result = np.zeros((*mask.shape,3))\n",
    "    for i in range(3):\n",
    "        result[...,i]=color[i]*mask\n",
    "    return result\n",
    "\n",
    "def RGB_image(image):\n",
    "    result = image-image.min() # [a,b] -> [0, b-a]\n",
    "    result = result/result.max() # [0, b-a] -> [0,1] -> [0,255]\n",
    "    return np.repeat(np.reshape(result[:,:,:], [image.shape[0],image.shape[1],image.shape[2],1]),3,axis=3)\n",
    "\n",
    "def visualize_3d_gif(image=None, actual_mask=None, predicted_mask=None, name_gif=\"array.gif\"):\n",
    "    if image is not None:\n",
    "        image = image.numpy().squeeze()\n",
    "        rgb_image = RGB_image(image)\n",
    "        result = rgb_image\n",
    "    for i in range(2):\n",
    "        mask = [actual_mask, predicted_mask][i]\n",
    "        if mask is not None:\n",
    "            mask = mask.numpy().squeeze()\n",
    "            rgb_mask = RGB_mask(mask, [color_actual, color_predicted][i])\n",
    "            if result is not None:\n",
    "                result += rgb_mask\n",
    "            else:\n",
    "                result = rgb_mask\n",
    "\n",
    "    result = result/np.max(result)*255\n",
    "    result = result.astype(np.uint8)\n",
    "    images = [PIL.Image.fromarray(result[:,:,index,:]) for index in range(image.shape[2])]\n",
    "    images[0].save(name_gif, save_all=True, append_images=images[1:],loop=0)\n",
    "\n",
    "def visualize_3d_masks(actual_mask=None, predicted_mask=None):\n",
    "    fig=plt.figure()\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    for i in range(2):\n",
    "        mask = [actual_mask, predicted_mask][i]\n",
    "        if mask is not None:\n",
    "            mask = mask.numpy().squeeze()\n",
    "            pos = np.where(mask==1)\n",
    "            ax.scatter(pos[0],pos[1],pos[2], color=[color_actual, color_predicted][i])\n",
    "\n",
    "    # multiple figures at different angles?\n",
    "    #ax.view_init(45, 0)\n",
    "    plt.show()    \n",
    "\n",
    "def visualize_histogram(image, mask):\n",
    "    image = image.numpy().squeeze()\n",
    "    mask = mask.numpy().squeeze()\n",
    "    fig, axs = plt.subplots(1, 2, tight_layout=True) \n",
    "    axs[0].hist(image[mask==0], bins=20)\n",
    "    axs[0].set_title(\"Background class\")\n",
    "    axs[1].hist(image[mask==1], bins=20)\n",
    "    axs[1].set_title(\"Vessel class\")   \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_3d_gif(image=validation_dataset[0][\"img\"], actual_mask=validation_dataset[0][\"mask\"])\n",
    "display(IPython.display.Image(data=open(\"array.gif\",'rb').read(), format='png'))\n",
    "visualize_3d_masks(actual_mask=validation_dataset[0][\"mask\"])\n",
    "visualize_histogram(validation_dataset[0][\"img\"],validation_dataset[0][\"mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_histogram_secret(original, secret):\n",
    "    original = original.numpy().squeeze().flatten()\n",
    "    secret = secret.numpy().squeeze().flatten()\n",
    "    fig, axs = plt.subplots(1, 2, tight_layout=True) \n",
    "    axs[0].hist(original, bins=20)\n",
    "    axs[0].set_title(\"Sample from original dataset\")\n",
    "    axs[1].hist(secret, bins=20)\n",
    "    axs[1].set_title(\"Sample from secret test dataset\")   \n",
    "    plt.show()\n",
    "    \n",
    "visualize_histogram_secret(validation_dataset[0][\"img\"], secrettest_dataset[0][\"img\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "train_loader = monai.data.DataLoader(train_dataset, batch_size=4, num_workers=8,pin_memory=torch.cuda.is_available())\n",
    "validation_loader = monai.data.DataLoader(validation_dataset, batch_size=1, num_workers=8,pin_memory=torch.cuda.is_available())\n",
    "secrettest_loader = monai.data.DataLoader(secrettest_dataset, batch_size=1, num_workers=8,pin_memory=torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:7\")\n",
    "model = monai.networks.nets.UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(8, 16, 32, 64, 128),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_function = monai.losses.DiceLoss(to_onehot_y=True, softmax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    project='ASOCAproject',\n",
    "    name='Test_crop256_5',\n",
    "    config={\n",
    "        'loss function': str(loss_function), \n",
    "        'lr': optimizer.param_groups[0][\"lr\"],\n",
    "        'batch_size': train_loader.batch_size,\n",
    "    }\n",
    ")\n",
    "# Do not hesitate to enrich this list of settings to be able to correctly keep track of your experiments!\n",
    "# For example you should add information on your model...\n",
    "\n",
    "run_id = run.id # We remember here the run ID to be able to write the evaluation metrics\n",
    "\n",
    "def log_to_wandb(epoch, train_loss, val_loss, batch_data):\n",
    "    \"\"\" Function that logs ongoing training variables to W&B \"\"\"\n",
    "    # This part is not yet working\n",
    "    # def log_to_wandb(epoch, train_loss, val_loss, batch_data, outputs):\n",
    "    # Create list of images that have segmentation masks for model output and ground truth\n",
    "    #log_imgs = [wandb.Image(img, masks=wandb_masks(mask_output, mask_gt)) for img, mask_output,\n",
    "    #            mask_gt in zip(batch_data['img'], outputs, batch_data['mask'])]\n",
    "\n",
    "    # Send epoch, losses and images to W&B\n",
    "    #wandb.log({'epoch': epoch, 'train_loss': train_loss, 'val_loss': val_loss, 'results': log_imgs})\n",
    "    wandb.log({'epoch': epoch, 'train_loss': train_loss, 'val_loss': val_loss})\n",
    "\n",
    "for epoch in tqdm(range(1000)):\n",
    "    # training\n",
    "    model.train()\n",
    "    epoch_loss=0\n",
    "    step=0\n",
    "    for batch in tqdm(train_loader, desc=\"Training Step\", leave=False, ncols=100):  # Nested tqdm for training steps\n",
    "        print(step)\n",
    "        step += 1\n",
    "        optimizer.zero_grad()\n",
    "        inputs = batch[\"img\"].to(device)\n",
    "        labels = batch[\"mask\"].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() \n",
    "    train_loss = epoch_loss / step\n",
    "    \n",
    "    # validation\n",
    "    step = 0\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(validation_loader, desc=\"Validation Step\", leave=False, ncols=100):  # Nested tqdm for training steps\n",
    "            print(step)\n",
    "            step += 1\n",
    "            model.eval()\n",
    "            inputs = batch[\"img\"].to(device)\n",
    "            labels = batch[\"mask\"].to(device)\n",
    "            outputs = sliding_window_inference(inputs, (256, 256, 128), 4, model)\n",
    "            #outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            val_loss+= loss.item()\n",
    "        val_loss = val_loss / step\n",
    "    \n",
    "    log_to_wandb(epoch, train_loss, val_loss, batch)\n",
    "    print(f\"Epoch {epoch+1}, Train loss: {train_loss:.4f}, Validation loss: {val_loss:.4f}\")\n",
    "    \n",
    "    torch.save(model.state_dict(),os.path.join(f\"Trained_crop256_v5\", f\"trainedUNet_epoch{epoch}.pt\"))\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Option to load a previous trained model, check path!\n",
    "model.load_state_dict(torch.load(r'Trained_crop256_v4/trainedUNet_epoch352.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visual_evaluation(sample, model):\n",
    "    \"\"\"\n",
    "    Allow the visual inspection of one sample by plotting the X-ray image, the ground truth (green)\n",
    "    and the segmentation map produced by the network (red).\n",
    "    \n",
    "    Args:\n",
    "        sample (Dict[str, torch.Tensor]): sample composed of an X-ray ('img') and a mask ('mask').\n",
    "        model (torch.nn.Module): trained model to evaluate.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    inferer = monai.inferers.SlidingWindowInferer(roi_size=[256, 256, 128])\n",
    "    discrete_transform = monai.transforms.AsDiscrete(logit_thresh=0.5, threshold_values=True)\n",
    "    Softmax = torch.nn.Softmax()\n",
    "    with torch.no_grad():\n",
    "        output = discrete_transform(Softmax(inferer(sample['img'].to('cuda:6'), network=model).cpu())).squeeze()\n",
    "        output = np.squeeze(output[1, :, :, :]).astype(np.uint8)\n",
    "    \n",
    "    fig, ax =plt.subplots(1,2, subplot_kw={\"projection\":\"3d\"})\n",
    "\n",
    "    actual_mask = np.squeeze(sample['mask'])\n",
    "    pos = np.where(actual_mask==1)\n",
    "    print(len(pos[0]))\n",
    "    ax[0].scatter(pos[0],pos[1],pos[2], color=color_actual)\n",
    "    \n",
    "    pos2 = np.where(output == 1)\n",
    "    print(len(pos2[0]))\n",
    "    ax[1].scatter(pos2[0],pos2[1],pos2[2], color=color_predicted)\n",
    "   \n",
    "    plt.show()\n",
    "    \n",
    "def visual_evaluationtest(sample, model):\n",
    "    \"\"\"\n",
    "    Allow the visual inspection of one sample by plotting the X-ray image, the ground truth (green)\n",
    "    and the segmentation map produced by the network (red).\n",
    "    \n",
    "    Args:\n",
    "        sample (Dict[str, torch.Tensor]): sample composed of an X-ray ('img') and a mask ('mask').\n",
    "        model (torch.nn.Module): trained model to evaluate.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    inferer = monai.inferers.SlidingWindowInferer(roi_size=[256, 256, 128])\n",
    "    discrete_transform = monai.transforms.AsDiscrete(logit_thresh=0.5, threshold_values=True)\n",
    "    Softmax = torch.nn.Softmax()\n",
    "    with torch.no_grad():\n",
    "        spatial_shape = sample['img'].meta['spatial_shape'].tolist()[0]\n",
    "        output = discrete_transform(Softmax(inferer(sample['img'].to('cuda:6'), network=model).cpu()))\n",
    "        output = torch.nn.Upsample(size=spatial_shape)(output)\n",
    "        output = output.squeeze().astype(np.uint8)\n",
    "        output = np.squeeze(output[1, :, :, :])\n",
    "        \n",
    "    original_affine = sample['img'].meta['original_affine'].detach().numpy()[0]\n",
    "    img_name = sample['img'].meta[\"filename_or_obj\"][0].split(\"/\")[-1].replace('img', 'mask')\n",
    "    nib.save(nib.Nifti1Image(output, original_affine), os.path.join('Output', img_name))\n",
    "    \n",
    "    fig, ax =plt.subplots(1, subplot_kw={\"projection\":\"3d\"})\n",
    "    pos2 = np.where(output == 1)\n",
    "    print(len(pos2[0]))\n",
    "    ax.scatter(pos2[0],pos2[1],pos2[2], color=color_predicted)\n",
    "   \n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sample in validation_loader:\n",
    "    visual_evaluation(sample, model.to('cuda:6'))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sample in secrettest_loader:\n",
    "    visual_evaluationtest(sample, model.to('cuda:6'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU memory\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if voxel size and dimensions match\n",
    "data = LoadImage(image_only=True, ensure_channel_first=True, simple_keys=True)('ASOCA_secret/1.img.nii.gz')\n",
    "print(data.pixdim)\n",
    "print(data.shape)\n",
    "\n",
    "data = LoadImage(image_only=True, ensure_channel_first=True, simple_keys=True)('Output/1.mask.nii.gz')\n",
    "print(data.pixdim)\n",
    "print(data.shape)\n",
    "fig = monai.visualize.matshow3d(monai.transforms.Orientation(\"SPL\")(data), every_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
